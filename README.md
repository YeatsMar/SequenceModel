# Sequence Model

## HMM

### Statistic Model

由于整个过程中全部都是概率连成，故而采用log处理，将连成全部改为连加，既加快运算效率，有解决了句子过长导致后期概率值几乎为零的精度问题。

最终统计模型基于train_corpus.utf8，保存在hmm_model.json中，全集正确率为0.8501340074226773。

## CRF

Implemented this model based on the paper *Discriminative training methods for hidden Markov models: Theory and experimentswith perceptron algorithms*. 

### Experiments

采用CRF++常用模板，B类增加B02

~~~
Template:
# Unigram
U01:%x[-1,0]
U02:%x[0,0]
U03:%x[1,0]
U05:%x[-2,0]/%x[-1,0]/%x[0,0]
U06:%x[-1,0]/%x[0,0]/%x[1,0]
U07:%x[0,0]/%x[1,0]/%x[2,0]
U08:%x[-1,0]/%x[0,0]
U09:%x[0,0]/%x[1,0]

# Bigram
B02:%x[0,0]
~~~



#### A

使用train.utf8训练，所有能观察到的80487个特征全部采纳，并初始化所有特征函数参数为0：

观察到准确率从最初30.6%（全部标记为B，该准确率接近最忌猜测值25%）逐步上升，在99.85%之后开始震荡，但仍可上升，在迭代29次后达到100%准确率。

![A](data/A.jpg)



#### B

在A的基础上，初始化特征函数参数为对应的特征函数观察到的出现次数，因此最初准确率已达83%，同样在99.8%之后开始震荡，迭代25次后也达到100%。

![B](data/B.png)



#### C

由于特征函数过多导致训练效率低下，尝试删去只出现过一次的特征函数，发现所需迭代次数从原来的20+到现在80+，过程中震荡较多，并且最高准确率仅有99.97%，之后标签几乎没有改变过。

![C](data/C.png)



#### D

尝试另一种减少特征函数的方法：在B的基础上，去除B02模板可见字，及B类模板充当HMM中的转移矩阵。

在train.utf8上迭代300次的准确率如下图：

![D](data/D.png)

在train_corpus.utf8上共生成602921个特征函数，训练结果如下：

由于训练集过大，迭代周期指数增长，故而迭代次数少很多，震荡表现得更明显，但实际和上图差不多，准确率略小于小语料。

![D2](data/D2.png)



#### E

仍然基于B的基础上，删去出现3次以下的特征函数：

train.utf8：震荡明显于之前的实验

![E](data/E.png)

train_corpus.utf8: 共327448特征函数，明显多于D实验，因为字的组合更多

准确率明显高于小预料

![E2](/Users/Mar/PycharmProjects/SequenceModel/data/E2.png)

#### F

考虑到train_corpus.utf8中共包含23444句子，删除1、2次出现的特征函数对于其训练可能微乎其微，故而此处采取删除1%即20次出现次数一下的特征函数，删减后只剩下36641个

（开始准确率很高的原因是……前面的被历史冲掉了_(:зゝ∠)_忘记采集了，真是尴尬）

![F](data/F.png)



#### G

之前所有迭代都是一次输入所有句子，再一起调整一下参数，在后续实验中采取神经网络中mini-batch的想法，每一次解析一句句子后就调整一下参数，虽然这样导致句子遍历顺序不一就会参数不同，存在很大偏差，但是大大提高了大语料库的训练效率。

train.utf8:

![G](data/G.png)

train_corpus.utf8为训练集，train.utf8为测试集：

![G2](data/G2.png)



~~~
there are 36641 feature functions in this model
0.8906559977900365 0.8588840433858884
0.9207818881376232 0.8809124454880912
0.9268072554163501 0.8629095381862909
0.9299329915584311 0.8768869506876887
0.9318326520225045 0.8753214804875321
0.9332886168901385 0.8650341048865035
0.9349877155920687 0.8677177680867718
0.9352630149919917 0.8810242647881025
0.9367397928726783 0.8839315665883931
0.9365543678473006 0.8778933243877893
0.9378864006826668 0.8772224085877223
0.937542985967299 0.8667113943866711
0.9383915892722162 0.8701777926870178
0.9386413454288474 0.8870625069887063
0.9386914858693832 0.8830370121883037
0.9394861645495732 0.8711841663871184
0.939610096581841 0.8724141786872415
0.9397472732587786 0.8459130045845913
0.9397595718574006 0.866040478586604
0.9402486776641367 0.8432293413843229
~~~

24310 最后model crf_perS.json是当前最好模型

参数：template2.utf，B类只有转移矩阵，过滤掉20次以下，每句话后都调参

~~~
there are 36641 feature functions in this model
0.8906559977900365 0.8588840433858884
0.9207818881376232 0.8809124454880912
0.9268072554163501 0.8629095381862909
0.9299329915584311 0.8768869506876887
0.9318326520225045 0.8753214804875321
0.9332886168901385 0.8650341048865035
0.9349877155920687 0.8677177680867718
0.9352630149919917 0.8810242647881025
0.9367397928726783 0.8839315665883931
0.9365543678473006 0.8778933243877893
0.9378864006826668 0.8772224085877223
0.937542985967299 0.8667113943866711
0.9383915892722162 0.8701777926870178
0.9386413454288474 0.8870625069887063
~~~





#### H

加上B02:%x[0,0]模板，仍然过滤出现20次以下的模板

![H](/Users/Mar/PycharmProjects/SequenceModel/data/H.png)

~~~
there are 41878 feature functions in this model
12mins/epoch
0.5988376878256172 0.5360617242536062
0.5939844716001706 0.5393044839539305
0.5931027566835788 0.5442245331544224
0.5926685215476178 0.5444481717544448
0.592447146772422 0.5431063401543106
0.5925181002260104 0.5436654366543665
0.5924263337593694 0.5442245331544224
0.592374301226738 0.5443363524544337
0.5923411896150633 0.5443363524544337
0.5924026826081733 0.5443363524544337
0.5923847077332642 0.5444481717544448
0.5923449737992547 0.5465727384546573
0.5923156463717715 0.5459018226545902
0.5923184845099151 0.5464609191546461
0.5923828156411686 0.5463490998546349
0.5922409087339917 0.5472436542547243
0.5923024017271017 0.5454545454545454
0.5923345672927284 0.5465727384546573
0.5922910491745276 0.5467963770546796
0.5923090240494365 0.5466845577546685
~~~



#### I

过滤出现3次以下模板



~~~
there are 234125 feature functions in this model
0.6116679643264956 0.5416526892541653
0.6072584436974885 0.5453427261545343
0.6066624346873459 0.5454545454545454
0.6064164627149062 0.5471318349547132
0.6064022720241885 0.5472436542547243
0.6063634841362269 0.5481382086548138
0.6063644301822747 0.5480263893548026
0.6064060562083798 0.547579112154758
0.6062991530049734 0.5466845577546685
0.6063653762283225 0.545790003354579
0.6063615920441312 0.5462372805546237
0.6062698255774902 0.5465727384546573
0.606368214366466 0.5467963770546796
~~~



#### J

Similar to D, just modify params after each sentence

session id: 24640

result2.json

../data/crf_perS2.json

~~~
there are 602921 feature functions in this model
0.9046527490679082 0.8939953035893995
0.9473695662662684 0.9036117633903612
0.958786449971666 0.90349994409035
0.9641770203522886 0.9079727160907972
0.9687643976382907 0.9077490774907749
0.9720746127597014 0.9123336687912333
0.9741861875384923 0.905959968690596
0.9761161214760967 0.9045063177904507
0.9773327366936259 0.9001453650900145
0.9788454643241306 0.8982444369898245
0.9806893080713811 0.8988035334898804
0.9813297812457723 0.9007044615900704
~~~

